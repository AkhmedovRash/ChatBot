import os, sys, random, numpy as np, pandas as pd
from PIL import Image
import tensorflow as tf
from tensorflow.keras import Input, Model
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, Conv2D, Conv2DTranspose, Activation, Flatten, Lambda, Concatenate, concatenate
from tensorflow.keras.optimizers import Adam
from matplotlib import pyplot as plt

def load_class_ids(p):
    import pickle
    with open(p, 'rb') as f:
        return pickle.load(f, encoding='latin1')

def load_embeddings(p):
    import pickle
    with open(p, 'rb') as f:
        e = pickle.load(f, encoding='latin1')
    return np.array(e)

def load_filenames(p):
    import pickle
    with open(p, 'rb') as f:
        return pickle.load(f, encoding='latin1')

def load_bounding_boxes(d):
    bb = os.path.join(d, 'bounding_boxes.txt')
    fp = os.path.join(d, 'images.txt')
    df_bb = pd.read_csv(bb, delim_whitespace=True, header=None).astype(int)
    df_fp = pd.read_csv(fp, delim_whitespace=True, header=None)
    file_names = df_fp[1].tolist()
    out = {}
    for i in range(len(file_names)):
        out[file_names[i][:-4]] = df_bb.iloc[i][1:].tolist()
    return out

def get_img(path, bbox, image_size):
    img = Image.open(path).convert('RGB')
    w, h = img.size
    if bbox is not None:
        R = int(max(bbox[2], bbox[3]) * 0.75)
        cx = int((2 * bbox[0] + bbox[2]) / 2)
        cy = int((2 * bbox[1] + bbox[3]) / 2)
        y1 = max(0, cy - R); y2 = min(h, cy + R)
        x1 = max(0, cx - R); x2 = min(w, cx + R)
        img = img.crop([x1, y1, x2, y2])
    img = img.resize(image_size, Image.BILINEAR)
    return img

def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):
    fn = load_filenames(filenames_file_path)
    cids = load_class_ids(class_info_file_path)
    bbs = load_bounding_boxes(cub_dataset_dir)
    all_emb = load_embeddings(embeddings_file_path)
    X, y, E = [], [], []
    for i, name in enumerate(fn):
        try:
            bb = bbs[name]
            img_path = f'{cub_dataset_dir}/images/{name}.jpg'
            img = get_img(img_path, bb, image_size)
            e1 = all_emb[i, :, :]
            ix = random.randint(0, e1.shape[0]-1)
            emb = e1[ix, :]
            X.append(np.array(img))
            y.append(cids[i])
            E.append(emb)
        except Exception as ex:
            continue
    return np.array(X), np.array(y), np.array(E)

def generate_c(x):
    m = x[:, :128]
    ls = x[:, 128:]
    std = K.exp(ls)
    eps = K.random_normal(shape=K.shape(m))
    return m + std * eps

def build_embedding_compressor_model():
    inp = Input(shape=(1024,))
    x = Dense(128)(inp)
    x = ReLU()(x)
    return Model(inp, x)

def build_stage1_generator():
    inp_txt = Input(shape=(1024,))
    h = Dense(256)(inp_txt)
    h = LeakyReLU(0.2)(h)
    mean_logsigma = h
    c = Lambda(generate_c)(mean_logsigma)
    inp_z = Input(shape=(100,))
    zc = Concatenate(axis=1)([c, inp_z])
    x = Dense(1024 * 4 * 4, use_bias=False)(zc)
    x = ReLU()(x)
    x = Reshape((4, 4, 1024))(x)
    x = Conv2DTranspose(512, 4, strides=2, padding="same", use_bias=False)(x)
    x = BatchNormalization()(x); x = ReLU()(x)
    x = Conv2DTranspose(256, 4, strides=2, padding="same", use_bias=False)(x)
    x = BatchNormalization()(x); x = ReLU()(x)
    x = Conv2DTranspose(128, 4, strides=2, padding="same", use_bias=False)(x)
    x = BatchNormalization()(x); x = ReLU()(x)
    x = Conv2DTranspose(64, 4, strides=2, padding="same", use_bias=False)(x)
    x = BatchNormalization()(x); x = ReLU()(x)
    x = Conv2D(3, 3, padding="same", use_bias=False)(x)
    out = Activation('tanh')(x)
    return Model([inp_txt, inp_z], [out, mean_logsigma])

def build_stage1_discriminator():
    inp_img = Input(shape=(64, 64, 3))
    x = Conv2D(64, 4, strides=2, padding='same', use_bias=False)(inp_img)
    x = LeakyReLU(0.2)(x)
    x = Conv2D(128, 4, strides=2, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x); x = LeakyReLU(0.2)(x)
    x = Conv2D(256, 4, strides=2, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x); x = LeakyReLU(0.2)(x)
    x = Conv2D(512, 4, strides=2, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x); x = LeakyReLU(0.2)(x)
    inp_c = Input(shape=(4, 4, 128))
    m = concatenate([x, inp_c])
    y = Conv2D(512, 1, padding="same", strides=1)(m)
    y = BatchNormalization()(y); y = LeakyReLU(0.2)(y)
    y = Flatten()(y)
    y = Dense(1)(y)
    out = Activation('sigmoid')(y)
    return Model([inp_img, inp_c], out)

def build_adversarial_model(gen, dis):
    txt = Input(shape=(1024,))
    z = Input(shape=(100,))
    cimg = Input(shape=(4, 4, 128))
    img, mls = gen([txt, z])
    dis.trainable = False
    valid = dis([img, cimg])
    return Model([txt, z, cimg], [valid, mls])

def KL_loss(y_true, y_pred):
    mean = y_pred[:, :128]
    logsigma = y_pred[:, 128:]
    loss = -logsigma + 0.5 * (-1 + K.exp(2. * logsigma) + K.square(mean))
    return K.mean(loss)

def save_rgb_img(img, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    fig = plt.figure(figsize=(2,2))
    ax = fig.add_subplot(1,1,1)
    ax.imshow((img * 127.5 + 127.5).astype(np.uint8))
    ax.axis("off")
    plt.savefig(path, bbox_inches='tight', pad_inches=0)
    plt.close(fig)

data_dir = "/content/birds"
train_dir = data_dir + "/train"
test_dir  = data_dir + "/test"
image_size = (64, 64)
batch_size = 64
z_dim = 100
epochs = 1000
condition_dim = 128
embeddings_file_path_train = train_dir + "/char-CNN-RNN-embeddings.pickle"
embeddings_file_path_test  = test_dir  + "/char-CNN-RNN-embeddings.pickle"
filenames_file_path_train  = train_dir + "/filenames.pickle"
filenames_file_path_test   = test_dir  + "/filenames.pickle"
class_info_file_path_train = train_dir + "/class_info.pickle"
class_info_file_path_test  = test_dir  + "/class_info.pickle"
cub_dataset_dir = "/content/CUB_200_2011"
os.makedirs("results", exist_ok=True)

X_train, y_train, E_train = load_dataset(filenames_file_path=filenames_file_path_train,
                                         class_info_file_path=class_info_file_path_train,
                                         cub_dataset_dir=cub_dataset_dir,
                                         embeddings_file_path=embeddings_file_path_train,
                                         image_size=image_size)

X_test, y_test, E_test = load_dataset(filenames_file_path=filenames_file_path_test,
                                      class_info_file_path=class_info_file_path_test,
                                      cub_dataset_dir=cub_dataset_dir,
                                      embeddings_file_path=embeddings_file_path_test,
                                      image_size=image_size)

dis_opt = Adam(learning_rate=2e-4, beta_1=0.5, beta_2=0.999)
gen_opt = Adam(learning_rate=2e-4, beta_1=0.5, beta_2=0.999)

D = build_stage1_discriminator()
D.compile(loss='binary_crossentropy', optimizer=dis_opt)

G = build_stage1_generator()
G.compile(loss="mse", optimizer=gen_opt)

C = build_embedding_compressor_model()
C.compile(loss="binary_crossentropy", optimizer="adam")

ADV = build_adversarial_model(G, D)
ADV.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1.0, 2.0], optimizer=gen_opt)

real_labels = np.ones((batch_size, 1), dtype=np.float32) * 0.9
fake_labels = np.zeros((batch_size, 1), dtype=np.float32) + 0.1
dummy_kl_targets = np.zeros((batch_size, 256), dtype=np.float32)

def to_tanh(x):
    return (x.astype(np.float32) - 127.5) / 127.5

steps_per_epoch = max(1, X_train.shape[0] // batch_size)
for epoch in range(epochs):
    gen_losses, dis_losses = [], []
    for b in range(steps_per_epoch):
        z = np.random.normal(0, 1, size=(batch_size, z_dim)).astype(np.float32)
        img_b = X_train[b*batch_size:(b+1)*batch_size]
        emb_b = E_train[b*batch_size:(b+1)*batch_size]
        if img_b.shape[0] < batch_size: continue
        img_b = to_tanh(img_b)
        fake_imgs, _ = G.predict([emb_b, z], verbose=0)
        comp = C.predict_on_batch(emb_b)
        comp = np.reshape(comp, (-1, 1, 1, condition_dim))
        comp = np.tile(comp, (1, 4, 4, 1))
        d_real = D.train_on_batch([img_b, comp], real_labels)
        d_fake = D.train_on_batch([fake_imgs, comp], fake_labels)
        d_wrong = D.train_on_batch([img_b[:batch_size-1], comp[1:]], fake_labels[1:])
        d_loss = 0.5 * (d_real + 0.5 * (d_wrong + d_fake))
        g_loss = ADV.train_on_batch([emb_b, z, comp], [real_labels, dummy_kl_targets])
        dis_losses.append(d_loss); gen_losses.append(g_loss[0] if isinstance(g_loss, (list, tuple)) else g_loss)
    if epoch % 2 == 0:
        z2 = np.random.normal(0, 1, size=(batch_size, z_dim)).astype(np.float32)
        emb_t = E_test[:batch_size]
        if emb_t.shape[0] == batch_size:
            imgs, _ = G.predict([emb_t, z2], verbose=0)
            for i, im in enumerate(imgs[:10]):
                save_rgb_img(im, f"results/gen_{epoch:04d}_{i}.png")

G.save_weights("stage1_gen.h5")
D.save_weights("stage1_dis.h5")
